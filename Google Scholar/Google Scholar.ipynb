{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Scholar and Semantic Scholar scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "\n",
    "# Request to Google Scholar\n",
    "url = 'https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q={Computational+Propaganda}&btnG='\n",
    "response=requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup=BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the title of the article\n",
    "results1 = []\n",
    "for entry in soup.find_all(\"h2\", attrs={\"class\": \"gs_rt\"}):\n",
    "    results1.append({\"Title\": entry.a.text})    \n",
    "dataframe1 = pd.DataFrame(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Authors, year, journal\n",
    "results2 = []\n",
    "for entry in soup.find_all(\"div\", attrs={\"class\": \"gs_a\"}):\n",
    "    year = re.findall('[0-9]+', entry.text)\n",
    "    journal = re.findall('[^-]+$', entry.text)\n",
    "    authors = re.findall('(^(.+?) - )', entry.text)\n",
    "    results2.append({\"Authors\": authors, \"Year\": year, \"Journal\": journal})\n",
    "dataframe2 = pd.DataFrame(results2)\n",
    "\n",
    "\n",
    "# Clean the data\n",
    "dataframe2['Authors'] = dataframe2['Authors'].str.get(0)\n",
    "dataframe2['Authors'] = dataframe2['Authors'].str.get(0)\n",
    "dataframe2['Journal'] = dataframe2['Journal'].str.get(0)\n",
    "dataframe2['Year'] = dataframe2['Year'].str.get(0)\n",
    "\n",
    "# Get the authors\n",
    "dataframe_temp = dataframe2['Authors'].str.extract('(^(.+?)- )')\n",
    "dataframe_temp.drop(dataframe_temp.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "# Concat the dataframes\n",
    "dataframe2 = pd.concat([dataframe_temp, dataframe2], axis=1)\n",
    "dataframe2.rename(columns={ dataframe2.columns[0]: \"Author\" }, inplace = True)\n",
    "dataframe2 = dataframe2.drop('Authors', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of citations for each paper\n",
    "results3 = []\n",
    "for entry in soup.find_all(\"div\", class_=\"gs_ri\"):\n",
    "    txt_cite = entry.find(\"div\", class_=\"gs_fl\").find_all(\"a\")[2].string\n",
    "    if txt_cite:\n",
    "        citations = re.findall('[0-9]+', txt_cite)\n",
    "        if citations:\n",
    "            results3.append({\"Number of citation\": citations})\n",
    "        else:\n",
    "            results3.append({\"Number of citation\": 0})\n",
    "    else:\n",
    "        results3.append({\"Number of citation\": 0})\n",
    "dataframe3 = pd.DataFrame(results3)\n",
    "# Clean the data\n",
    "dataframe3['Number of citation'] = dataframe3['Number of citation'].str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the link\n",
    "results4 = []\n",
    "\n",
    "for entry in soup.find_all('h3', class_ = 'gs_rt'):\n",
    "    results4.append({\"Link\": entry.a['href']})\n",
    "dataframe4 = pd.DataFrame(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Number of citation</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SC Woolley, P Howard</td>\n",
       "      <td>2017</td>\n",
       "      <td>ora.ox.ac.uk</td>\n",
       "      <td>230</td>\n",
       "      <td>https://ora.ox.ac.uk/objects/uuid:d6157461-aef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GDS Martino, S Cresci, A Barrón-Cedeño, S Yu…</td>\n",
       "      <td>2020</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>97</td>\n",
       "      <td>https://arxiv.org/abs/2007.08024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LMN Neudert</td>\n",
       "      <td>2017</td>\n",
       "      <td>demtech.oii.ox.ac.uk</td>\n",
       "      <td>48</td>\n",
       "      <td>https://demtech.oii.ox.ac.uk/wp-content/upload...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SC Woolley, PN Howard</td>\n",
       "      <td>2016</td>\n",
       "      <td>par.nsf.gov</td>\n",
       "      <td>249</td>\n",
       "      <td>https://par.nsf.gov/biblio/10021331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SC Woolley, PN Howard</td>\n",
       "      <td>2018</td>\n",
       "      <td>books.google.com</td>\n",
       "      <td>463</td>\n",
       "      <td>https://books.google.com/books?hl=en&amp;lr=&amp;id=qT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SC Woolley, D Guilbeault</td>\n",
       "      <td>2017</td>\n",
       "      <td>ora.ox.ac.uk</td>\n",
       "      <td>129</td>\n",
       "      <td>https://ora.ox.ac.uk/objects/uuid:620ce18f-69e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D Arnaudo</td>\n",
       "      <td>2017</td>\n",
       "      <td>ora.ox.ac.uk</td>\n",
       "      <td>135</td>\n",
       "      <td>https://ora.ox.ac.uk/objects/uuid:e88de32c-baa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G Bolsover, P Howard</td>\n",
       "      <td>2017</td>\n",
       "      <td>liebertpub.com</td>\n",
       "      <td>97</td>\n",
       "      <td>https://www.liebertpub.com/doi/full/10.1089/bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S Sanovich</td>\n",
       "      <td>2017</td>\n",
       "      <td>ora.ox.ac.uk</td>\n",
       "      <td>116</td>\n",
       "      <td>https://ora.ox.ac.uk/objects/uuid:555c1e20-60d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R DiResta</td>\n",
       "      <td>2018</td>\n",
       "      <td>muse.jhu.edu</td>\n",
       "      <td>30</td>\n",
       "      <td>https://muse.jhu.edu/pub/1/article/791857/summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Author  Year  \\\n",
       "0                           SC Woolley, P Howard   2017   \n",
       "1  GDS Martino, S Cresci, A Barrón-Cedeño, S Yu…   2020   \n",
       "2                                    LMN Neudert   2017   \n",
       "3                          SC Woolley, PN Howard   2016   \n",
       "4                          SC Woolley, PN Howard   2018   \n",
       "5                       SC Woolley, D Guilbeault   2017   \n",
       "6                                      D Arnaudo   2017   \n",
       "7                           G Bolsover, P Howard   2017   \n",
       "8                                     S Sanovich   2017   \n",
       "9                                      R DiResta   2018   \n",
       "\n",
       "                 Journal Number of citation  \\\n",
       "0           ora.ox.ac.uk                230   \n",
       "1              arxiv.org                 97   \n",
       "2   demtech.oii.ox.ac.uk                 48   \n",
       "3            par.nsf.gov                249   \n",
       "4       books.google.com                463   \n",
       "5           ora.ox.ac.uk                129   \n",
       "6           ora.ox.ac.uk                135   \n",
       "7         liebertpub.com                 97   \n",
       "8           ora.ox.ac.uk                116   \n",
       "9           muse.jhu.edu                 30   \n",
       "\n",
       "                                                Link  \n",
       "0  https://ora.ox.ac.uk/objects/uuid:d6157461-aef...  \n",
       "1                   https://arxiv.org/abs/2007.08024  \n",
       "2  https://demtech.oii.ox.ac.uk/wp-content/upload...  \n",
       "3                https://par.nsf.gov/biblio/10021331  \n",
       "4  https://books.google.com/books?hl=en&lr=&id=qT...  \n",
       "5  https://ora.ox.ac.uk/objects/uuid:620ce18f-69e...  \n",
       "6  https://ora.ox.ac.uk/objects/uuid:e88de32c-baa...  \n",
       "7  https://www.liebertpub.com/doi/full/10.1089/bi...  \n",
       "8  https://ora.ox.ac.uk/objects/uuid:555c1e20-60d...  \n",
       "9  https://muse.jhu.edu/pub/1/article/791857/summary  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat the dataframes and clean the dataset\n",
    "dataframe = pd.concat([dataframe1, dataframe2,dataframe3,dataframe4], axis=1)\n",
    "dataframe.to_csv('Google Scholar - publications', sep='\\t')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URL of the paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computational propaganda project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chinese computational propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oxford computational propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computational propaganda political communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computational propaganda autonomous agents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>computational propaganda worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>computational propaganda uk eu referendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>computational propaganda bots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Suggestion\n",
       "0                  computational propaganda project\n",
       "1                  chinese computational propaganda\n",
       "2                   oxford computational propaganda\n",
       "3  computational propaganda political communication\n",
       "4        computational propaganda autonomous agents\n",
       "5                computational propaganda worldwide\n",
       "6         computational propaganda uk eu referendum\n",
       "7                     computational propaganda bots"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract suggested results\n",
    "results_suggestion = []\n",
    "for entry in soup.find_all(\"div\", attrs={\"class\": \"gs_qsuggest gs_qsuggest_regular\"}):\n",
    "    for item in entry.find_all(\"li\"):\n",
    "        results_suggestion.append({\"Suggestion\": item.text})\n",
    "dataframe_suggestion = pd.DataFrame(results_suggestion)\n",
    "dataframe_suggestion.to_csv('Google Scholar - suggestions', sep='\\t')\n",
    "dataframe_suggestion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
